{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Spam Filter using Naive Bayes\n",
    "\n",
    "The purpose of this project is to create a spam filter using the multinomial Naive Bayes algorithm. We will use a data set of 5,572 SMS messages that have already been classified by humans. We will use this __[data](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection)__ collected by Tiago A. Almeida and José María Gómez Hidalgo to help \"teach\" the computer how to classify messages into spam and non-spam. Our goal is to write a program that is over 80% accurate.\n",
    "\n",
    "## Exploring the Dataset\n",
    "\n",
    "Let's start by reading in the data and getting familiar with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#sep ='\\t' for tab separated data, not csv, no header, names create column labels\n",
    "sms_spam = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names =['Label', 'SMS'])\n",
    "\n",
    "print(sms_spam.shape)\n",
    "sms_spam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see that about 87% of the SMS messages are non-spam, with the remaining being spam. This sample seems representative, since in practice most messages a person receives are ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ham means non-spam\n",
    "#percentage of each type\n",
    "sms_spam['Label'].value_counts(normalize = True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Set\n",
    "\n",
    "We will now split our SMS data into a training and a test data set. We will use 80% of the data for training and 20% for testing our spam filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "#randomizing rows of the data\n",
    "sms_random = sms_spam.sample(frac=1, random_state = 1)\n",
    "\n",
    "#calculating number of rows to use for training\n",
    "training_set_index = round(len(sms_spam.index) * .8)\n",
    "\n",
    "#splitting data\n",
    "training_set = sms_random[0:training_set_index].reset_index(drop=True)\n",
    "test_set = sms_random[training_set_index:].reset_index(drop=True)\n",
    "\n",
    "#check row counts\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we divided the data into a training set and a test set, let's examine the percentages of spam and ham to check for similarity to entire dataset. We are looking for around 87% ham and 13% spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     86.54105\n",
      "spam    13.45895\n",
      "Name: Label, dtype: float64 \n",
      "\n",
      "ham     86.804309\n",
      "spam    13.195691\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(training_set['Label'].value_counts(normalize=True) * 100, '\\n')\n",
    "print(test_set['Label'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results look good. We will proceed by cleaning the dataset.\n",
    "\n",
    "## Cleaning Data\n",
    "\n",
    "In order to calculate all the probabilities, we need for our algorithm, we will need to get the data into a format that is easily extractable.\n",
    "\n",
    "Essentially, we want to get from the top format to the bottom format:\n",
    "\n",
    "| | Label| SMS |\n",
    "| --- | --- | --- |\n",
    "| 0 | spam | WINNER! MUST CLAIM NOW! CLAIM BIG PRIZE! |\n",
    "| 1 | ham | Coming to my big party? |\n",
    "| 2 | spam | Winner! Claim Government money. |\n",
    "\n",
    "| | Label | winner | must | claim | now | big | prize | coming | to | my | party | government | money |\n",
    "| --- | --- | --- | ---| ---| --- | --- | --- | --- | --- | --- | --- | --- | ---|\n",
    "| 0 | spam | 1 | 1 | 2 | 1 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "| 1 | ham  | 0 | 0 | 0 | 0 | 1 | 0 | 1 | 1 | 1 | 1 | 0 | 0 |\n",
    "| 2 | spam | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 |\n",
    "\n",
    "### Punctuation and Case\n",
    "\n",
    "We will begin by cleaning the SMS messages. Below, we will strip the messages of punctuation and make all the letters lower case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       Yep, by the pretty sculpture\n",
       "1   ham      Yes, princess. Are you going to make me moan?\n",
       "2   ham                         Welp apparently he retired\n",
       "3   ham                                            Havent.\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#before cleaning for ease of checking\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['SMS'] = training_set['SMS'].str.replace('\\W', ' ')\n",
    "training_set['SMS'] = training_set['SMS'].str.lower()\n",
    "#after cleaning\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Vocabulary\n",
    "\n",
    "Below we will create a vocabulary of all the words in the SMS messages. This will be a list of all the unique words in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                  [yep, by, the, pretty, sculpture]\n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...\n",
       "2   ham                    [welp, apparently, he, retired]\n",
       "3   ham                                           [havent]\n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating vocab from words in training set messages\n",
    "training_set['SMS'] = training_set['SMS'].str.split()\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are 7,783 unique words in our training set's SMS messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = []\n",
    "\n",
    "for row in training_set['SMS']:\n",
    "    for word in row:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "vocabulary = list(set(vocabulary))      \n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The Final Training Set\n",
    "\n",
    "Now that we have our vocabulary for the training set, we can transform our dataset into the desired form. We will have each column represent a word from our training set vocabulary. The values in each column and row are determined by the number of times the word appears in each message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize dictionary\n",
    "word_counts_per_sms = {unique_word : [0] * len(training_set['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "#get word counts for words in each message using index\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v</th>\n",
       "      <th>realise</th>\n",
       "      <th>tablet</th>\n",
       "      <th>actual</th>\n",
       "      <th>cann</th>\n",
       "      <th>landline</th>\n",
       "      <th>school</th>\n",
       "      <th>ticket</th>\n",
       "      <th>supreme</th>\n",
       "      <th>scream</th>\n",
       "      <th>...</th>\n",
       "      <th>jsco</th>\n",
       "      <th>carryin</th>\n",
       "      <th>keralacircle</th>\n",
       "      <th>platt</th>\n",
       "      <th>35p</th>\n",
       "      <th>wise</th>\n",
       "      <th>sad</th>\n",
       "      <th>withdraw</th>\n",
       "      <th>salary</th>\n",
       "      <th>preferably</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   v  realise  tablet  actual  cann  landline  school  ticket  supreme  \\\n",
       "0  0        0       0       0     0         0       0       0        0   \n",
       "1  0        0       0       0     0         0       0       0        0   \n",
       "2  0        0       0       0     0         0       0       0        0   \n",
       "3  0        0       0       0     0         0       0       0        0   \n",
       "4  0        0       0       0     0         0       0       0        0   \n",
       "\n",
       "   scream  ...  jsco  carryin  keralacircle  platt  35p  wise  sad  withdraw  \\\n",
       "0       0  ...     0        0             0      0    0     0    0         0   \n",
       "1       0  ...     0        0             0      0    0     0    0         0   \n",
       "2       0  ...     0        0             0      0    0     0    0         0   \n",
       "3       0  ...     0        0             0      0    0     0    0         0   \n",
       "4       0  ...     0        0             0      0    0     0    0         0   \n",
       "\n",
       "   salary  preferably  \n",
       "0       0           0  \n",
       "1       0           0  \n",
       "2       0           0  \n",
       "3       0           0  \n",
       "4       0           0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform dictionary to dataframe\n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our dictionary for our vocabulary of words, we will create a combined dataframe. It will include: the vocabulary dictionary, the ham/spam `Label` and the list of words in each SMS message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>v</th>\n",
       "      <th>realise</th>\n",
       "      <th>tablet</th>\n",
       "      <th>actual</th>\n",
       "      <th>cann</th>\n",
       "      <th>landline</th>\n",
       "      <th>school</th>\n",
       "      <th>ticket</th>\n",
       "      <th>...</th>\n",
       "      <th>jsco</th>\n",
       "      <th>carryin</th>\n",
       "      <th>keralacircle</th>\n",
       "      <th>platt</th>\n",
       "      <th>35p</th>\n",
       "      <th>wise</th>\n",
       "      <th>sad</th>\n",
       "      <th>withdraw</th>\n",
       "      <th>salary</th>\n",
       "      <th>preferably</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  v  realise  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]  0        0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...  0        0   \n",
       "2   ham                    [welp, apparently, he, retired]  0        0   \n",
       "3   ham                                           [havent]  0        0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  0        0   \n",
       "\n",
       "   tablet  actual  cann  landline  school  ticket  ...  jsco  carryin  \\\n",
       "0       0       0     0         0       0       0  ...     0        0   \n",
       "1       0       0     0         0       0       0  ...     0        0   \n",
       "2       0       0     0         0       0       0  ...     0        0   \n",
       "3       0       0     0         0       0       0  ...     0        0   \n",
       "4       0       0     0         0       0       0  ...     0        0   \n",
       "\n",
       "   keralacircle  platt  35p  wise  sad  withdraw  salary  preferably  \n",
       "0             0      0    0     0    0         0       0           0  \n",
       "1             0      0    0     0    0         0       0           0  \n",
       "2             0      0    0     0    0         0       0           0  \n",
       "3             0      0    0     0    0         0       0           0  \n",
       "4             0      0    0     0    0         0       0           0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_clean = pd.concat([training_set, word_counts], axis=1)\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Constants for Filter\n",
    "\n",
    "We are done cleaning the training set. Now we can start creating the spam filter. We will be using the Naive Bayes algorithm to classify emails as spam or ham. We will answer the two probability problems below in order to classify the emails.\n",
    "\n",
    "_$$P(Spam|w_1, w_2,.......w_n) \\alpha P(Spam)\\cdot \\prod_{i=1}^{n}P(w_i|Spam)$$_\n",
    "_$$P(Ham|w_1, w_2,.......w_n) \\alpha P(Ham)\\cdot \\prod_{i=1}^{n}P(w_i|Ham)$$_\n",
    "\n",
    "In addition, we will need to calculate $P(w_i|Spam)$ and $P(w_i|Ham)$ in the formulas above. We need to use the following equations:\n",
    "\n",
    "_$$P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}$$_\n",
    "\n",
    "_$$P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}$$_\n",
    "\n",
    "Also, some of the terms in the four equations above will maintain their value for each new message. We can avoid duplicate computations each time a new message comes in by calculating each of these terms once below. We will use our training set to calculate:\n",
    "\n",
    "- $P(Spam)$ and $P(Ham)$\n",
    "- $N_{Spam}, N_{Ham}, N_{Vocabulary}$\n",
    "\n",
    "We will also use Laplace smoothing here to avoid any multiplying by zero issues and set $\\alpha$ = 1.\n",
    "\n",
    "The constants are calculated below. We split the messages from our training set by `Label`. Then we will perform the necessary calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate spam and ham messages from training set\n",
    "spam_messages = training_set_clean[training_set_clean['Label'] == 'spam']\n",
    "ham_messages = training_set_clean[training_set_clean['Label'] == 'ham']\n",
    "\n",
    "#P(spam) and P(ham) training set\n",
    "p_spam = len(spam_messages) / len(training_set_clean)\n",
    "p_ham = len(ham_messages)/ len(training_set_clean)\n",
    "\n",
    "# N_spam\n",
    "num_words_per_spam = spam_messages['SMS'].apply(len)\n",
    "n_spam = num_words_per_spam.sum()\n",
    "\n",
    "#N_ham\n",
    "num_words_per_ham = ham_messages['SMS'].apply(len)\n",
    "n_ham = num_words_per_ham.sum()\n",
    "\n",
    "# N_vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "#LaPlace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Parameters\n",
    "\n",
    "Now that we have calculated the constants we need above; we can proceed with computing the parameters $P(w_i|Spam)$ and $P(w_i|Ham)$. Each of these will be a conditional probability value associated with each word in the vocabulary of our training set.\n",
    "\n",
    "The following formulas are used for calculating the parameters:\n",
    "\n",
    "_$$P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}$$_\n",
    "\n",
    "_$$P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}$$_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing parameters\n",
    "parameters_ham = {unique_word : 0 for unique_word in vocabulary}\n",
    "parameters_spam = {unique_word : 0 for unique_word in vocabulary}\n",
    "\n",
    "#Calculate parameters\n",
    "for word in vocabulary:\n",
    "    n_words_given_ham = ham_messages[word].sum()\n",
    "    p_word_given_ham = (n_words_given_ham + alpha) /(n_ham + alpha * n_vocabulary)\n",
    "    parameters_ham[word] = p_word_given_ham\n",
    "    \n",
    "    n_words_given_spam = spam_messages[word].sum()\n",
    "    p_word_given_spam = (n_words_given_spam + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "    parameters_spam[word] = p_word_given_spam "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying a New Message\n",
    "\n",
    "Now that we have calculated our constants and parameters we can begin building the spam filter. Our spam filter is described as a function that performs the following:\n",
    "\n",
    "- Takes in input as a message $(w_1, w_2,...w_n)$\n",
    "- Calculates the probabilities $P(Spam|w_1, w_2,...w_n)$ and $P(Ham|w_1, w_2,...w_n)$\n",
    "- Compares $P(Spam|w_1, w_2,...w_n)$ and $P(Ham|w_1, w_2,...w_n)$ and:\n",
    "    - If $P(Ham|w_1, w_2,...w_n) > P(Spam|w_1, w_2,...w_n)$, classifies the message as ham.\n",
    "    -  If $P(Spam|w_1, w_2,...w_n) > P(Ham|w_1, w_2,...w_n)$, classifies the message as spam.\n",
    "    - If $P(Spam|w_1, w_2,...w_n) = P(Ham|w_1, w_2,...w_n)$, asks for human help to classify the message.\n",
    "    \n",
    "Below is our function to classify messages as either ham or spam.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing fuction to classify messages \n",
    "import re\n",
    "\n",
    "def classify(message):\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    ''' \n",
    "    message: a string\n",
    "    '''\n",
    "    \n",
    "    p_ham_given_message = p_ham\n",
    "    p_spam_given_message = p_spam\n",
    "    \n",
    "    for word in message:\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "            \n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "    \n",
    "    \n",
    "    print('P(spam|message):', p_ham_given_message)\n",
    "    print('P(ham|message):', p_spam_given_message)\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Probabilities are equal, ask for human help classifying this!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will test our classifying message on a couple of messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(spam|message): 1.9368049028589875e-27\n",
      "P(ham|message): 1.3481290211300841e-25\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(spam|message): 3.687530435009238e-21\n",
      "P(ham|message): 2.4372375665888117e-25\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify('Sounds good, Tom, then see u there')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the Spam Filter's Accuracy\n",
    "\n",
    "Now that we have our function written and have seen it works, we need to determine how accurate it is. We will use our test set of 1,114 messages we established earlier.\n",
    "\n",
    "We will write a function below that will return classification labels from the messages instead of printing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    p_ham_given_message = p_ham\n",
    "    p_spam_given_message = p_spam\n",
    "    \n",
    "    for word in message:\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "            \n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'Probabilities are equal, seek human help!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a function that returns classification labels, we can create a new column in our test set data to help facilitate checking for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now write a function to check the accuracy of our filter with the test set data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1100\n",
      "Incorrect: 14\n",
      "Accuracy: 0.9874\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(test_set.index)\n",
    "\n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "        \n",
    "        \n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', (total - correct))\n",
    "print('Accuracy:', round(correct/total, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see above that our accuracy was 98.74%. Our filter looked at 1,114 messages it had not seen before and correctly classified 1,100 of them. \n",
    "\n",
    "## Analyzing Incorrect Classifications\n",
    "\n",
    "Although our accuracy was good, we will examine the 14 messages below that were incorrectly classified and look for reasons the algorithm may have classified incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>spam</td>\n",
       "      <td>Not heard from U4 a while. Call me now am here...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>spam</td>\n",
       "      <td>More people are dogging in your area now. Call...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>ham</td>\n",
       "      <td>Unlimited texts. Limited minutes.</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>ham</td>\n",
       "      <td>26th OF JULY</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nokia phone is lovly..</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>ham</td>\n",
       "      <td>A Boy loved a gal. He propsd bt she didnt mind...</td>\n",
       "      <td>Probabilities are equal, seek human help!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>ham</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319</td>\n",
       "      <td>ham</td>\n",
       "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>spam</td>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546</td>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>741</td>\n",
       "      <td>spam</td>\n",
       "      <td>0A$NETWORKS allow companies to bill for SMS, s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>876</td>\n",
       "      <td>spam</td>\n",
       "      <td>RCT' THNQ Adrian for U text. Rgds Vatian</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885</td>\n",
       "      <td>spam</td>\n",
       "      <td>2/2 146tf150p</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>953</td>\n",
       "      <td>spam</td>\n",
       "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label                                                SMS  \\\n",
       "114  spam  Not heard from U4 a while. Call me now am here...   \n",
       "135  spam  More people are dogging in your area now. Call...   \n",
       "152   ham                  Unlimited texts. Limited minutes.   \n",
       "159   ham                                       26th OF JULY   \n",
       "284   ham                             Nokia phone is lovly..   \n",
       "293   ham  A Boy loved a gal. He propsd bt she didnt mind...   \n",
       "302   ham                   No calls..messages..missed calls   \n",
       "319   ham  We have sent JD for Customer Service cum Accou...   \n",
       "504  spam  Oh my god! I've found your number again! I'm s...   \n",
       "546  spam  Hi babe its Chloe, how r u? I was smashed on s...   \n",
       "741  spam  0A$NETWORKS allow companies to bill for SMS, s...   \n",
       "876  spam           RCT' THNQ Adrian for U text. Rgds Vatian   \n",
       "885  spam                                      2/2 146tf150p   \n",
       "953  spam  Hello. We need some posh birds and chaps to us...   \n",
       "\n",
       "                                     predicted  \n",
       "114                                        ham  \n",
       "135                                        ham  \n",
       "152                                       spam  \n",
       "159                                       spam  \n",
       "284                                       spam  \n",
       "293  Probabilities are equal, seek human help!  \n",
       "302                                       spam  \n",
       "319                                       spam  \n",
       "504                                        ham  \n",
       "546                                        ham  \n",
       "741                                        ham  \n",
       "876                                        ham  \n",
       "885                                        ham  \n",
       "953                                        ham  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect = test_set[test_set['Label'] != test_set['predicted']]\n",
    "incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect ham classification percentage is 0.6205%.\n",
      "Incorrect spam classification percentage is 5.4422%.\n"
     ]
    }
   ],
   "source": [
    "incorrect_ham_pct = (len(incorrect[incorrect['Label'] == 'ham'])/ len(test_set[test_set['Label'] == 'ham'])) * 100\n",
    "print('Incorrect ham classification percentage is {}%.'.format(round(incorrect_ham_pct, 4)))\n",
    "\n",
    "incorrect_spam_pct = (len(incorrect[incorrect['Label'] == 'spam'])/ len(test_set[test_set['Label'] == 'spam'])) * 100\n",
    "print('Incorrect spam classification percentage is {}%.'.format(round(incorrect_spam_pct, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a few observations from the above information. The filter did a little worse, in terms of percentage incorrect, at recognizing spam messages. A significant amount of capitalization appears in the incorrect messages. There was also one message with equal probability, which was likely the result of the words in that SMS message not reappearing in our vocabulary elsewhere. \n",
    "\n",
    "## Filter with Case Sensitivity\n",
    "\n",
    "Using our observations, we will now make our filter case sensitive and check to see if we improve our accuracy. We will start by getting our training and test sets once again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1114, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting training and test sets for case sensitive filter\n",
    "training_set_two = sms_random[0:training_set_index].reset_index(drop=True)\n",
    "print(training_set_two.shape)\n",
    "\n",
    "test_set_two = sms_random[training_set_index:].reset_index(drop=True)\n",
    "test_set_two.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Case Sensitive Data\n",
    "\n",
    "Next we will clean the data without adjusting all the words to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Yes  princess  Are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>Havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth   There s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       Yep  by the pretty sculpture\n",
       "1   ham      Yes  princess  Are you going to make me moan \n",
       "2   ham                         Welp apparently he retired\n",
       "3   ham                                            Havent \n",
       "4   ham  I forgot 2 ask ü all smth   There s a card on ..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning data, no case adjustment\n",
    "training_set_two['SMS'] = training_set_two['SMS'].str.replace('\\W', ' ')\n",
    "\n",
    "training_set_two.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Sensitive Vocabulary\n",
    "\n",
    "Now that we have our data in a good clean format, we will establish our new version of the vocabulary with case sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_two['SMS'] = training_set_two['SMS'].str.split()\n",
    "\n",
    "vocabulary_two = []\n",
    "\n",
    "for row in training_set_two['SMS']:\n",
    "    for word in row:\n",
    "        vocabulary_two.append(word)\n",
    "        \n",
    "vocabulary_two = list(set(vocabulary_two)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9656"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new case sensitive vocabulary has 9,656 words. This is about a 24% increase in vocabulary words compared to our first iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize dictionary\n",
    "word_counts_per_sms_two = {unique_word : [0] * len(training_set_two['SMS']) for unique_word in vocabulary_two}\n",
    "\n",
    "#get word counts for words in each message\n",
    "for index, sms in enumerate(training_set_two['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms_two[word][index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retest with Case Sensitive Vocabulary\n",
    "\n",
    "Now that we have our new vocabulary that is case sensitive, we will use it with our training set and test set and review the accuracy of the test set classifications. Below we will get our training set into the format we would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baaaaaaaabe</th>\n",
       "      <th>v</th>\n",
       "      <th>realise</th>\n",
       "      <th>tablet</th>\n",
       "      <th>actual</th>\n",
       "      <th>cann</th>\n",
       "      <th>SWAN</th>\n",
       "      <th>Unfortunately</th>\n",
       "      <th>landline</th>\n",
       "      <th>school</th>\n",
       "      <th>...</th>\n",
       "      <th>Cost</th>\n",
       "      <th>carryin</th>\n",
       "      <th>35p</th>\n",
       "      <th>wise</th>\n",
       "      <th>sad</th>\n",
       "      <th>withdraw</th>\n",
       "      <th>Gay</th>\n",
       "      <th>Algarve</th>\n",
       "      <th>salary</th>\n",
       "      <th>preferably</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9656 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Baaaaaaaabe  v  realise  tablet  actual  cann  SWAN  Unfortunately  \\\n",
       "0            0  0        0       0       0     0     0              0   \n",
       "1            0  0        0       0       0     0     0              0   \n",
       "2            0  0        0       0       0     0     0              0   \n",
       "3            0  0        0       0       0     0     0              0   \n",
       "4            0  0        0       0       0     0     0              0   \n",
       "\n",
       "   landline  school  ...  Cost  carryin  35p  wise  sad  withdraw  Gay  \\\n",
       "0         0       0  ...     0        0    0     0    0         0    0   \n",
       "1         0       0  ...     0        0    0     0    0         0    0   \n",
       "2         0       0  ...     0        0    0     0    0         0    0   \n",
       "3         0       0  ...     0        0    0     0    0         0    0   \n",
       "4         0       0  ...     0        0    0     0    0         0    0   \n",
       "\n",
       "   Algarve  salary  preferably  \n",
       "0        0       0           0  \n",
       "1        0       0           0  \n",
       "2        0       0           0  \n",
       "3        0       0           0  \n",
       "4        0       0           0  \n",
       "\n",
       "[5 rows x 9656 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform dictionary to dataframe\n",
    "word_counts_two = pd.DataFrame(word_counts_per_sms_two)\n",
    "\n",
    "#needed to rename column because SMS was in new vocabulary\n",
    "word_counts_two.rename(columns = {'SMS':'SmS'}, inplace = True)\n",
    "\n",
    "word_counts_two.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>Baaaaaaaabe</th>\n",
       "      <th>v</th>\n",
       "      <th>realise</th>\n",
       "      <th>tablet</th>\n",
       "      <th>actual</th>\n",
       "      <th>cann</th>\n",
       "      <th>SWAN</th>\n",
       "      <th>Unfortunately</th>\n",
       "      <th>...</th>\n",
       "      <th>Cost</th>\n",
       "      <th>carryin</th>\n",
       "      <th>35p</th>\n",
       "      <th>wise</th>\n",
       "      <th>sad</th>\n",
       "      <th>withdraw</th>\n",
       "      <th>Gay</th>\n",
       "      <th>Algarve</th>\n",
       "      <th>salary</th>\n",
       "      <th>preferably</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>[Yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>[Yes, princess, Are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ham</td>\n",
       "      <td>[Welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>[Havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>[I, forgot, 2, ask, ü, all, smth, There, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9658 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  Baaaaaaaabe  v  \\\n",
       "0   ham                  [Yep, by, the, pretty, sculpture]            0  0   \n",
       "1   ham  [Yes, princess, Are, you, going, to, make, me,...            0  0   \n",
       "2   ham                    [Welp, apparently, he, retired]            0  0   \n",
       "3   ham                                           [Havent]            0  0   \n",
       "4   ham  [I, forgot, 2, ask, ü, all, smth, There, s, a,...            0  0   \n",
       "\n",
       "   realise  tablet  actual  cann  SWAN  Unfortunately  ...  Cost  carryin  \\\n",
       "0        0       0       0     0     0              0  ...     0        0   \n",
       "1        0       0       0     0     0              0  ...     0        0   \n",
       "2        0       0       0     0     0              0  ...     0        0   \n",
       "3        0       0       0     0     0              0  ...     0        0   \n",
       "4        0       0       0     0     0              0  ...     0        0   \n",
       "\n",
       "   35p  wise  sad  withdraw  Gay  Algarve  salary  preferably  \n",
       "0    0     0    0         0    0        0       0           0  \n",
       "1    0     0    0         0    0        0       0           0  \n",
       "2    0     0    0         0    0        0       0           0  \n",
       "3    0     0    0         0    0        0       0           0  \n",
       "4    0     0    0         0    0        0       0           0  \n",
       "\n",
       "[5 rows x 9658 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_clean_two = pd.concat([training_set_two, word_counts_two], axis=1)\n",
    "training_set_clean_two.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recalculate constants\n",
    "\n",
    "Most of the constants will be the same for the case sensitive case. We have chosen to show all of them again. These calculations are only performed one time and therefore they don't cost a lot of computational time. This also makes it easier to separate our training trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate spam and ham messages from training set\n",
    "spam_messages_two = training_set_clean_two[training_set_clean_two['Label'] == 'spam']\n",
    "ham_messages_two = training_set_clean_two[training_set_clean_two['Label'] == 'ham']\n",
    "\n",
    "#P(spam) and P(ham) training set\n",
    "p_spam = len(spam_messages) / len(training_set_clean)\n",
    "p_ham = len(ham_messages)/ len(training_set_clean)\n",
    "\n",
    "# N_spam\n",
    "num_words_per_spam = spam_messages_two['SMS'].apply(len)\n",
    "n_spam = num_words_per_spam.sum()\n",
    "\n",
    "#N_ham\n",
    "num_words_per_ham = ham_messages_two['SMS'].apply(len)\n",
    "n_ham = num_words_per_ham.sum()\n",
    "\n",
    "# N_vocabulary\n",
    "n_vocabulary_two = len(vocabulary_two)\n",
    "\n",
    "#LaPlace smoothing\n",
    "alpha = 1\n",
    "#vocabulary_two = [list(s) for s in vocabulary_two]\n",
    "vocabulary_two[0:30]\n",
    "vocabulary_two = list(vocabulary_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recalculate Parameters\n",
    "\n",
    "Now we will recalculate our parameters using the new vocabulary and word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Initializing parametersparameters_ham = {unique_word : 0 for unique_word in vocabulary}\n",
    "parameters_spam_two = {unique_word : 0 for unique_word in vocabulary_two}\n",
    "parameters_ham_two = {unique_word : 0 for unique_word in vocabulary_two}\n",
    "\n",
    "for word in training_set_clean_two.columns[2:9658]:\n",
    "    n_words_given_ham_two = ham_messages_two[word].sum()\n",
    "    p_word_given_ham_two = (n_words_given_ham_two + alpha) / (n_ham + alpha * n_vocabulary_two)\n",
    "    parameters_ham_two[word] = p_word_given_ham_two\n",
    "    \n",
    "    n_words_given_spam_two = spam_messages_two[word].sum()\n",
    "    p_word_given_spam_two = (n_words_given_spam_two + alpha) / (n_spam + alpha * n_vocabulary_two)\n",
    "    parameters_spam_two[word] = p_word_given_spam_two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure Case Sensitive Filter Accuracy\n",
    "\n",
    "We will run our test set SMS messages through our case sensitive filter below and then check our results for accuracy. Our function will work the same as the one did for our case insensitive function:\n",
    "\n",
    "- Takes in input as a message $(w_1, w_2,...w_n)$\n",
    "- Calculates the probabilities $P(Spam|w_1, w_2,...w_n)$ and $P(Ham|w_1, w_2,...w_n)$ using case sensitive vocabulary\n",
    "- Compares $P(Spam|w_1, w_2,...w_n)$ and $P(Ham|w_1, w_2,...w_n)$ and:\n",
    "    - If $P(Ham|w_1, w_2,...w_n) > P(Spam|w_1, w_2,...w_n)$, classifies the message as ham.\n",
    "    -  If $P(Spam|w_1, w_2,...w_n) > P(Ham|w_1, w_2,...w_n)$, classifies the message as spam.\n",
    "    - If $P(Spam|w_1, w_2,...w_n) = P(Ham|w_1, w_2,...w_n)$, asks for human help to classify the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set_two(message):\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.split()\n",
    "    \n",
    "    p_ham_given_message = p_ham\n",
    "    p_spam_given_message = p_spam\n",
    "    \n",
    "    for word in message:\n",
    "        if word in parameters_ham_two:\n",
    "            p_ham_given_message *= parameters_ham_two[word]\n",
    "            \n",
    "        if word in parameters_spam_two:\n",
    "            p_spam_given_message *= parameters_spam_two[word]\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'Probabilities are equal, seek human help!'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "      <th>predicted_two</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted  \\\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham   \n",
       "1   ham             But i haf enuff space got like 4 mb...       ham   \n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam   \n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham   \n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham   \n",
       "\n",
       "  predicted_two  \n",
       "0           ham  \n",
       "1           ham  \n",
       "2          spam  \n",
       "3           ham  \n",
       "4           ham  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted_two'] = test_set['SMS'].apply(classify_test_set_two)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1092\n",
      "Incorrect: 22\n",
      "Accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(test_set.index)\n",
    "\n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted_two']:\n",
    "        correct += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', (total - correct))\n",
    "print('Accuracy:', round(correct/total, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "      <th>predicted_two</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>spam</td>\n",
       "      <td>goldviking (29/M) is inviting you to be his fr...</td>\n",
       "      <td>spam</td>\n",
       "      <td>Probabilities are equal, seek human help!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>spam</td>\n",
       "      <td>Not heard from U4 a while. Call me now am here...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>ham</td>\n",
       "      <td>1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cance...</td>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>spam</td>\n",
       "      <td>More people are dogging in your area now. Call...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>ham</td>\n",
       "      <td>Please protect yourself from e-threats. SIB ne...</td>\n",
       "      <td>ham</td>\n",
       "      <td>Probabilities are equal, seek human help!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nokia phone is lovly..</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>ham</td>\n",
       "      <td>A Boy loved a gal. He propsd bt she didnt mind...</td>\n",
       "      <td>Probabilities are equal, seek human help!</td>\n",
       "      <td>Probabilities are equal, seek human help!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319</td>\n",
       "      <td>ham</td>\n",
       "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323</td>\n",
       "      <td>ham</td>\n",
       "      <td>CHEERS U TEX MECAUSE U WEREBORED! YEAH OKDEN H...</td>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>363</td>\n",
       "      <td>spam</td>\n",
       "      <td>Email AlertFrom: Jeri StewartSize: 2KBSubject:...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385</td>\n",
       "      <td>spam</td>\n",
       "      <td>-PLS STOP bootydelious (32/F) is inviting you ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>Probabilities are equal, seek human help!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>spam</td>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546</td>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>664</td>\n",
       "      <td>ham</td>\n",
       "      <td>G.W.R</td>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>741</td>\n",
       "      <td>spam</td>\n",
       "      <td>0A$NETWORKS allow companies to bill for SMS, s...</td>\n",
       "      <td>ham</td>\n",
       "      <td>Probabilities are equal, seek human help!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>863</td>\n",
       "      <td>ham</td>\n",
       "      <td>CAN I PLEASE COME UP NOW IMIN TOWN.DONTMATTER ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>876</td>\n",
       "      <td>spam</td>\n",
       "      <td>RCT' THNQ Adrian for U text. Rgds Vatian</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885</td>\n",
       "      <td>spam</td>\n",
       "      <td>2/2 146tf150p</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>953</td>\n",
       "      <td>spam</td>\n",
       "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>967</td>\n",
       "      <td>spam</td>\n",
       "      <td>+123 Congratulations - in this week's competit...</td>\n",
       "      <td>spam</td>\n",
       "      <td>Probabilities are equal, seek human help!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1004</td>\n",
       "      <td>ham</td>\n",
       "      <td>Please protect yourself from e-threats. SIB ne...</td>\n",
       "      <td>ham</td>\n",
       "      <td>Probabilities are equal, seek human help!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1073</td>\n",
       "      <td>ham</td>\n",
       "      <td>I (Career Tel) have added u as a contact on IN...</td>\n",
       "      <td>ham</td>\n",
       "      <td>Probabilities are equal, seek human help!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS  \\\n",
       "89    spam  goldviking (29/M) is inviting you to be his fr...   \n",
       "114   spam  Not heard from U4 a while. Call me now am here...   \n",
       "115    ham  1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cance...   \n",
       "135   spam  More people are dogging in your area now. Call...   \n",
       "218    ham  Please protect yourself from e-threats. SIB ne...   \n",
       "284    ham                             Nokia phone is lovly..   \n",
       "293    ham  A Boy loved a gal. He propsd bt she didnt mind...   \n",
       "319    ham  We have sent JD for Customer Service cum Accou...   \n",
       "323    ham  CHEERS U TEX MECAUSE U WEREBORED! YEAH OKDEN H...   \n",
       "363   spam  Email AlertFrom: Jeri StewartSize: 2KBSubject:...   \n",
       "385   spam  -PLS STOP bootydelious (32/F) is inviting you ...   \n",
       "504   spam  Oh my god! I've found your number again! I'm s...   \n",
       "546   spam  Hi babe its Chloe, how r u? I was smashed on s...   \n",
       "664    ham                                              G.W.R   \n",
       "741   spam  0A$NETWORKS allow companies to bill for SMS, s...   \n",
       "863    ham  CAN I PLEASE COME UP NOW IMIN TOWN.DONTMATTER ...   \n",
       "876   spam           RCT' THNQ Adrian for U text. Rgds Vatian   \n",
       "885   spam                                      2/2 146tf150p   \n",
       "953   spam  Hello. We need some posh birds and chaps to us...   \n",
       "967   spam  +123 Congratulations - in this week's competit...   \n",
       "1004   ham  Please protect yourself from e-threats. SIB ne...   \n",
       "1073   ham  I (Career Tel) have added u as a contact on IN...   \n",
       "\n",
       "                                      predicted  \\\n",
       "89                                         spam   \n",
       "114                                         ham   \n",
       "115                                         ham   \n",
       "135                                         ham   \n",
       "218                                         ham   \n",
       "284                                        spam   \n",
       "293   Probabilities are equal, seek human help!   \n",
       "319                                        spam   \n",
       "323                                         ham   \n",
       "363                                        spam   \n",
       "385                                        spam   \n",
       "504                                         ham   \n",
       "546                                         ham   \n",
       "664                                         ham   \n",
       "741                                         ham   \n",
       "863                                         ham   \n",
       "876                                         ham   \n",
       "885                                         ham   \n",
       "953                                         ham   \n",
       "967                                        spam   \n",
       "1004                                        ham   \n",
       "1073                                        ham   \n",
       "\n",
       "                                  predicted_two  \n",
       "89    Probabilities are equal, seek human help!  \n",
       "114                                         ham  \n",
       "115                                        spam  \n",
       "135                                         ham  \n",
       "218   Probabilities are equal, seek human help!  \n",
       "284                                        spam  \n",
       "293   Probabilities are equal, seek human help!  \n",
       "319                                        spam  \n",
       "323                                        spam  \n",
       "363                                         ham  \n",
       "385   Probabilities are equal, seek human help!  \n",
       "504                                         ham  \n",
       "546                                         ham  \n",
       "664                                        spam  \n",
       "741   Probabilities are equal, seek human help!  \n",
       "863                                        spam  \n",
       "876                                         ham  \n",
       "885                                         ham  \n",
       "953                                         ham  \n",
       "967   Probabilities are equal, seek human help!  \n",
       "1004  Probabilities are equal, seek human help!  \n",
       "1073  Probabilities are equal, seek human help!  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining results\n",
    "incorrect_two = test_set[test_set['Label'] != test_set['predicted_two']]\n",
    "incorrect_two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we can see that our second filter isn't quite as accurate on our test set. It showed a larger number of equal probabilities, likely due to the increased vocabulary list and more words not reappearing in other SMS messages. The second filter did do a better job of catching spam messages. It correctly captured 3 of the 5 spam messages, the case insensitive filter missed. \n",
    "\n",
    "## Combined Filter\n",
    "\n",
    "Based on what we have seen thus far, it appears that we should be able to get a little better accuracy if we combine both filters. The case insensitive filter had better accuracy with the ham messages, so we will use that filter's feature. The case sensitive filter did well at recognizing spam messages that the case insensitive filter thought were ham. We will use the good attributes from each to create a combined filter. Our combined filter will:\n",
    "\n",
    "- Takes in input as a message $(w_1, w_2,...w_n)$\n",
    "- Calculates the probabilities $P(Spam|w_1, w_2,...w_n)$ and $P(Ham|w_1, w_2,...w_n)$ using all _lower case_ vocabulary\n",
    "- Compares $P(Spam|w_1, w_2,...w_n)$ and $P(Ham|w_1, w_2,...w_n)$ and:\n",
    "    - If $P(Ham|w_1, w_2,...w_n) > P(Spam|w_1, w_2,...w_n)$, classifies the message as ham.  \n",
    "    - If $P(Spam|w_1, w_2,...w_n) = P(Ham|w_1, w_2,...w_n)$, asks for human help to classify the message.\n",
    "    - If $P(Spam|w_1, w_2,...w_n) > P(Ham|w_1, w_2,...w_n)$, message is further analyzed:\n",
    "        - Calculates the probabilities $P(Spam|w_1, w_2,...w_n)$ and $P(Ham|w_1, w_2,...w_n)$ using _case sensitive_ vocabulary\n",
    "        - Compares $P(Spam|w_1, w_2,...w_n)$ and $P(Ham|w_1, w_2,...w_n)$ and:\n",
    "            - If $P(Ham|w_1, w_2,...w_n) > P(Spam|w_1, w_2,...w_n)$, classifies the message as ham.\n",
    "            - Otherwise, classifies the message as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set_combined(message):\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.split()\n",
    "    \n",
    "    p_ham_given_message = p_ham\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message_two = p_ham\n",
    "    p_spam_given_message_two = p_spam\n",
    "    \n",
    "    for word in message:\n",
    "        word_lower = word.lower()\n",
    "        if word_lower in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word_lower]\n",
    "            \n",
    "        if word_lower in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word_lower]\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message == p_spam_given_message:\n",
    "        return 'Equal probability, seek human help!'\n",
    "    else: \n",
    "        for word in message:\n",
    "            if word in parameters_ham_two:\n",
    "                p_ham_given_message_two *= parameters_ham_two[word]\n",
    "            \n",
    "            if word in parameters_spam_two:\n",
    "                p_spam_given_message_two *= parameters_spam_two[word]\n",
    "    \n",
    "        if p_ham_given_message_two > p_spam_given_message_two:\n",
    "            return 'ham'\n",
    "        else:\n",
    "            return 'spam'               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "      <th>predicted_two</th>\n",
       "      <th>predicted_three</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted  \\\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham   \n",
       "1   ham             But i haf enuff space got like 4 mb...       ham   \n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam   \n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham   \n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham   \n",
       "\n",
       "  predicted_two predicted_three  \n",
       "0           ham             ham  \n",
       "1           ham             ham  \n",
       "2          spam            spam  \n",
       "3           ham             ham  \n",
       "4           ham             ham  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining results from all three trials\n",
    "test_set['predicted_three'] = test_set['SMS'].apply(classify_test_set_combined)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1102\n",
      "Incorrect: 12\n",
      "Accuracy: 0.9892\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(test_set.index)\n",
    "\n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted_three']:\n",
    "        correct += 1\n",
    "        \n",
    "        \n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', (total - correct))\n",
    "print('Accuracy:', round(correct/total, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "      <th>predicted_two</th>\n",
       "      <th>predicted_three</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>spam</td>\n",
       "      <td>Not heard from U4 a while. Call me now am here...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>spam</td>\n",
       "      <td>More people are dogging in your area now. Call...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nokia phone is lovly..</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>ham</td>\n",
       "      <td>A Boy loved a gal. He propsd bt she didnt mind...</td>\n",
       "      <td>Probabilities are equal, seek human help!</td>\n",
       "      <td>Probabilities are equal, seek human help!</td>\n",
       "      <td>Equal probability, seek human help!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319</td>\n",
       "      <td>ham</td>\n",
       "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>363</td>\n",
       "      <td>spam</td>\n",
       "      <td>Email AlertFrom: Jeri StewartSize: 2KBSubject:...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>spam</td>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546</td>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>741</td>\n",
       "      <td>spam</td>\n",
       "      <td>0A$NETWORKS allow companies to bill for SMS, s...</td>\n",
       "      <td>ham</td>\n",
       "      <td>Probabilities are equal, seek human help!</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>876</td>\n",
       "      <td>spam</td>\n",
       "      <td>RCT' THNQ Adrian for U text. Rgds Vatian</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885</td>\n",
       "      <td>spam</td>\n",
       "      <td>2/2 146tf150p</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>953</td>\n",
       "      <td>spam</td>\n",
       "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label                                                SMS  \\\n",
       "114  spam  Not heard from U4 a while. Call me now am here...   \n",
       "135  spam  More people are dogging in your area now. Call...   \n",
       "284   ham                             Nokia phone is lovly..   \n",
       "293   ham  A Boy loved a gal. He propsd bt she didnt mind...   \n",
       "319   ham  We have sent JD for Customer Service cum Accou...   \n",
       "363  spam  Email AlertFrom: Jeri StewartSize: 2KBSubject:...   \n",
       "504  spam  Oh my god! I've found your number again! I'm s...   \n",
       "546  spam  Hi babe its Chloe, how r u? I was smashed on s...   \n",
       "741  spam  0A$NETWORKS allow companies to bill for SMS, s...   \n",
       "876  spam           RCT' THNQ Adrian for U text. Rgds Vatian   \n",
       "885  spam                                      2/2 146tf150p   \n",
       "953  spam  Hello. We need some posh birds and chaps to us...   \n",
       "\n",
       "                                     predicted  \\\n",
       "114                                        ham   \n",
       "135                                        ham   \n",
       "284                                       spam   \n",
       "293  Probabilities are equal, seek human help!   \n",
       "319                                       spam   \n",
       "363                                       spam   \n",
       "504                                        ham   \n",
       "546                                        ham   \n",
       "741                                        ham   \n",
       "876                                        ham   \n",
       "885                                        ham   \n",
       "953                                        ham   \n",
       "\n",
       "                                 predicted_two  \\\n",
       "114                                        ham   \n",
       "135                                        ham   \n",
       "284                                       spam   \n",
       "293  Probabilities are equal, seek human help!   \n",
       "319                                       spam   \n",
       "363                                        ham   \n",
       "504                                        ham   \n",
       "546                                        ham   \n",
       "741  Probabilities are equal, seek human help!   \n",
       "876                                        ham   \n",
       "885                                        ham   \n",
       "953                                        ham   \n",
       "\n",
       "                         predicted_three  \n",
       "114                                  ham  \n",
       "135                                  ham  \n",
       "284                                 spam  \n",
       "293  Equal probability, seek human help!  \n",
       "319                                 spam  \n",
       "363                                  ham  \n",
       "504                                  ham  \n",
       "546                                  ham  \n",
       "741                                  ham  \n",
       "876                                  ham  \n",
       "885                                  ham  \n",
       "953                                  ham  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_three = test_set[test_set['Label'] != test_set['predicted_three']]\n",
    "incorrect_three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We were able to create a spam filter using the Naive Bayes algorithm with conditional probability. We used two different vocabularies for our filter. One was case sensitive, one was not. They both had an admirable accuracy of over 98% on our test set. Then we used a combination of both versions of the filter, capitalizing on their respective good features. Using this approach almost, we increased to nearly 99%  accuracy on our test set.\n",
    "\n",
    "Our results here were quite good and we achieved our goal. Next steps could be to expand the vocabulary used and test filter on another data set. The dataset used was not particularly large.  There are over 171,000 words in the __[ Oxford English Dictionary](https://www.lexico.com/en/explore/how-many-words-are-there-in-the-english-language)__ and our _larger_ vocabulary had less than 10,000 words. Additionally, an unbiased new set of data would help determine our current filter's practicality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
